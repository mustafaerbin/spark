version: '3'
services:

  spark:
    image: bitnami/spark:latest
    container_name: spark
    environment:
      - SPARK_MODE=master
    ports:
      - "8085:8080"  # Spark için 8085 portu harici olarak atanıyor
    volumes:
      - ./spark-jobs:/opt/spark/jobs
    networks:
      - my_network

  minio:
    image: quay.io/minio/minio:latest
    container_name: minio
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password123
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"  # MinIO için port
      - "9001:9001"  # MinIO konsol arayüzü
    volumes:
      - minio_data:/data
    networks:
      - my_network

  airflow-webserver:
    image: apache/airflow:2.6.2
    container_name: airflow-webserver
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./dags:/opt/airflow/dags  # DAG'ler için yerel dosya yolu
      - ./logs:/opt/airflow/logs  # Loglar için yerel dosya yolu
      - ./plugins:/opt/airflow/plugins  # Eklentiler için yerel dosya yolu
    ports:
      - "8081:8080"  # Airflow webserver için port
    command: >
      bash -c "airflow db init &&
               airflow users create --username admin --password admin --firstname admin --lastname admin --role Admin --email admin@example.com &&
               airflow webserver"
    depends_on:
      - spark
      - minio
    networks:
      - my_network

  airflow-scheduler:
    image: apache/airflow:2.6.2
    container_name: airflow-scheduler
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: >
      bash -c "airflow scheduler"
    depends_on:
      - airflow-webserver
    networks:
      - my_network

volumes:
  minio_data:

networks:
  my_network:
    driver: bridge
